{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "vital-engineer",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Face' from 'benchmark' (D:\\P\\mgr\\face-detection-ml\\benchmark\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-e29da809cc57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../benchmark/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbenchmark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Face' from 'benchmark' (D:\\P\\mgr\\face-detection-ml\\benchmark\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import cv2\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from time import perf_counter_ns\n",
    "\n",
    "sys.path.append('../benchmark/')\n",
    "from benchmark import Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "written-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "honey-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_home = '../AFLW/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "designed-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../AFLW/aflw.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "pending-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"SELECT image_id, filepath, Faces.face_id, x, y, w, h FROM FaceImages, Faces, FaceRect WHERE FaceImages.file_id = Faces.file_id AND Faces.face_id = FaceRect.face_id LIMIT 50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "liberal-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "desirable-america",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4d9cff32ccb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mface_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox_counter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mbox_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Box' is not defined"
     ]
    }
   ],
   "source": [
    "image_data_dict = {}\n",
    "\n",
    "for row in c.execute(query_string):\n",
    "    file_path = str(row[1])\n",
    "    input_path = images_home + '/' + file_path\n",
    "    \n",
    "    if(os.path.isfile(input_path) == True):\n",
    "        image_id = row[0]\n",
    "        face_id = row[2]\n",
    "        face_x = row[3]\n",
    "        face_y = row[4]\n",
    "        face_w = row[5]\n",
    "        face_h = row[6]\n",
    "        \n",
    "        face = Face(face_id, Box(box_counter, face_x, face_y, face_w, face_h))\n",
    "        box_counter += 1\n",
    "        \n",
    "        if image_id in image_data_dict:\n",
    "            image_data_dict[image_id].add_face(face)\n",
    "        else:\n",
    "            img_face = ImageFaces(image_id, input_path)\n",
    "            img_face.add_face(face)\n",
    "            \n",
    "            image_data_dict[image_id] = img_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-equilibrium",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for face_image in image_data_dict.values():\n",
    "    box_id = 0\n",
    "    img = cv2.imread(face_image.image_path)\n",
    "    \n",
    "    t1_start = perf_counter_ns()\n",
    "    faces = face_classifier.detectMultiScale(\n",
    "            img,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "    t1_stop = perf_counter_ns()\n",
    "    \n",
    "    boxes = []\n",
    "    for f in faces:\n",
    "        boxes.append(Box(box_id, f[0], f[1], f[2], f[3]))\n",
    "        box_id += 1\n",
    "    \n",
    "    acc = face_image.calculate_prediction(boxes)\n",
    "    acc.stats()\n",
    "    \n",
    "    pred = Prediction(t1_stop-t1_start, acc)\n",
    "    print(pred.stats())\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-class",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
